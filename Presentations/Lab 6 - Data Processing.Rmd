---
title: "Data Processing"
subtitle: "R for Stata Users"
date: "November-December 2018"
author: "Luiza Andrade, Leonardo Viotti & Rob Marty "
output:
  beamer_presentation:
    #theme: "Pittsburgh"
    theme: "Madrid"
    colortheme: "whale"
    fonttheme: "default"
    toc: true
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo = F, eval=T}
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})


# File paths

if (Sys.getenv("USERNAME") == "luiza"){
  projectFolder  <- "C:/Users/luiza/Documents/GitHub/dime-r-training"
  
}

if (Sys.getenv("USERNAME") == "WB501238"){
  projectFolder  <- "C:/Users/WB501238/Documents/GitHub/dime-r-training"
  
}

if (Sys.getenv("USERNAME") == "Leonardo"){
  projectFolder  <- "C:/Users/Leonardo/Documents/GitHub/dime-r-training"
  
}

if (Sys.getenv("USERNAME") == "WB519128"){
  projectFolder <- file.path("C:/Users/WB519128/Documents/GitHub/dime-r-training")
}

library(tidyverse)
library(readstata13)

# File paths
dataWorkFolder    <- file.path(projectFolder,"DataWork")

Data              <- file.path(dataWorkFolder,"DataSets")
finalData         <- file.path(Data,"Final")
rawData           <- file.path(Data,"Raw")

```

# Introduction


## Introduction

* The goal of this session is to recreate the WHR data set that we've been using for this training
* We'll take you through the same steps we've taken when we were preparing it
* We'll use a set of packages that are bundled into something called the `tidyverse`

## Introduction

* In this session, you'll be introduced to some basic concepts of data cleaning in R. The contents covered are:
    * Exploring a data set
    * Creating new variables
    * Filtering and subsetting data sets
    * Dealing with factor variables
    * Merging and reshaping data sets
    * Saving data
* There are many other tasks that we usually perform as part of data cleaning that are beyond the scope of this session



## Introduction

Before we start, let's make sure we're all set:

  1. Start a fresh session.
  2. Make sure the `tidyverse` package is listed in the `packages` vector of your Master script. If it's are not installed, install it.
  3. Run the Master script to load all the necessary packages and set file paths.
  4. Remember to disable the `PACKAGES` switch in the Master script if you already installed the necessary packages. This will save you a lot of time.


## Introduction

Here's a shortcut if you missed the last session:

\scriptsize

```{r, eval= F}
  # Install packages
  install.packages("tidyverse",
                   dependencies = TRUE)

  # Load packages
  library(tidyverse)

  #  Set folder paths
  projectFolder <- "YOUR/FOLDER/PATH"
  finalData     <- file.path(projectFolder, "DataWork", "DataSets", "Final")
  rawlData      <- file.path(projectFolder, "DataWork", "DataSets", "Raw")

```

## Loading the data

### Exercise 1: Load data
Load the three `WHR` data sets from `DataWork > DataSets > Raw`. Create an object called `whrYY` with each data set.

 * TIP: use the ``file.path()`` function and the ``rawData`` object created in the master to simplify the folder path.


## Loading a data set from CSV

```{r}
# Load the data sets (we'll discuss why the 
# stringsAsFactors argument is necessary soon)
whr15 <- read.csv(file.path(Data,"Raw/WHR2015.csv"),
                  header = TRUE,
                  stringsAsFactors = FALSE)

whr16 <- read.csv(file.path(Data,"Raw/WHR2016.csv"),
                  header = TRUE,
                  stringsAsFactors = FALSE)

whr17 <- read.csv(file.path(Data,"Raw/WHR2017.csv"),
                  header = TRUE,
                  stringsAsFactors = FALSE)
  
```

## Loading a data set from CSV

* R reads string variables as factors as default
* This format saves memory, but can be tricky if you actually want to use the variables as strings (which is rarely the case)
* You can specify the option ``stringsAsFactors = FALSE`` to prevent R from turning strings into factors
* You can also simply recast any variables you want to be strings (as they'll probably be just a few) using the ``as.character()`` function


# Exploring a data set

## Exploring a data set

Some useful functions:

* **``View()``:** open the data set
* **``class()``:** reports object type or type of data stored
* **``dim()``:** reports the size of each one of an object's dimension
* **``names()``:** returns the variable names of a data set
* **``str()``:** general information on an R object
* **``summary()``:** summary information about the variables in a data frame
* **``head()``:** shows the first few observations in the dataset
* **``tail()``:** shows the last few observations in the dataset

## Exploring a data set

### Exercise 2: Explore a data set

Use some of the functions listed above to explore the `whr15` data set.

## Exploring a data set

\footnotesize
```{r, eval = F}
# View the data set (same as clickin on it in the Environment pane)
View(whr15)
```
\begin{figure}
\centering
  \includegraphics[scale=0.4]{img/View.png}
\end{figure}

## Exploring a data set

\footnotesize
```{r}
class(whr15)
dim(whr15)
```

## Exploring a data set

\footnotesize
```{r}
str(whr15)
```

## Exploring a data set

```{r, size = "tiny"}
summary(whr15)
```

## Exploring a data set

\footnotesize
```{r, size = "tiny"}
head(whr15)
```

# ID variables

## ID variables

Desired properties of an ID variable: *uniquely and fully identifying*

* An ID variable cannot have duplicates
* An ID variable may never be missing
* The ID variable must be constant across a project
* The ID variable must be anonymous

## ID variables


### ``n_distinct(..., na.rm = FALSE)``  

Counts the number of unique values of a variablelength of a vector

 * **...**: a vector of values
 * **na.rm**: if `TRUE`, missing values don't count
 
### Exercise 3: identify the ID

Using the `n_distinct` function, can you tell if the following variables are IDs of the `whr15` data set?

1. Region
2. Country

## ID variables

```{r}
dim(whr15)
n_distinct(whr15$Region, na.rm = TRUE)
n_distinct(whr15$Country, na.rm = TRUE)
```

## ID variables

```{r}
n_distinct(whr16$Country, na.rm = TRUE) == nrow(whr16)

n_distinct(whr17$Country, na.rm = TRUE) == nrow(whr17)
```

## ID variables
  
 * The data set we've been using in the last few sessions combines all three data sets we have now
 * Before we combine them, we should take a better look at the ID variables to find out if they are consistent


## Comparing vectors

### ``setdiff(first, second)``
Lists all the elements of the `first` object that are not in the `second` object (ignores duplicates).

* **first:** an object
* **second:** an (other?) object

## Comparing vectors

### Exercise 4: compare vectors
Use the `setdiff()` function to see which countries are coming in and out of the WHR data set between 2015 and 2016.

## Comparing vectors

```{r}
# Any countries in 2015 that are not in 2016?
setdiff(whr15$Country, whr16$Country)

# And vice-versa
setdiff(whr16$Country, whr15$Country)
```

## Replacing values

Wait, "Somaliland region" and "Somaliland Region" are not the same?!

### Exercise 5: replacing values
Replace the occurrences of "Somaliland region" in whr15 with "Somaliland **R**egion".

- TIP: use indexing to select only the observations of whr15$Country that are equal to "Somaliland region"

## Replacing values

Wait, "Somaliland region" and "Somaliland Region" are not the same?!
```{r}
# Now they are:
whr15$Country[whr15$Country == "Somaliland region"] <-
  "Somaliland Region"
```

## Replacing values

We also did the same for 2017:

```{r, size = "footnotesize"}
# Compare countries
setdiff(whr16$Country, whr17$Country)
setdiff(whr17$Country, whr16$Country)

# Fix names
whr17$Country[whr17$Country == "Hong Kong S.A.R., China"]  <- "Hong Kong" 
whr17$Country[whr17$Country == "Taiwan Province of China"] <- "Taiwan" 
```

## Creating variables
  
  * Ok, the ID variables are consistent now
  * But once we merge the data sets, we need to still be able to identify them
  * So let's add a `year` variable so we can tell them apart

### Exercise 6: creating variables
Create a variable called `year` in each WHR data set identifying what year it refers to,

## Creating variables

```{r}
# Piece of cake!
whr15$year <- 2015
whr16$year <- 2016
whr17$year <- 2017
```

# Appending and merging data sets

## Appending data sets

  * Now that we can identify the observations, we can combine the data set
  * Here's a function to append objects by row:
 
### ``rbind(...)``
Take a sequence of vector, matrix or data-frame arguments and combine by rows.

* **...:** vectors or matrices to be combined

## Appending and merging

### Exercise 7: append data sets
Use the `rbind` function to append the three WHR datasets into a data set called `whr_panel`.

## Appending and merging data sets

```{r, eval = F}
# Append data sets
whr_panel <- rbind(whr15, whr16, whr17)
```
\textcolor{red}{\texttt{Error in rbind(deparse.level, ...) : \\ numbers of columns of arguments do not match}}

## Appending data sets

  * Our data sets are still too different to use this function, as it has very strong requirements
  * There's a number of ways to fix this, and we will explore them soon
  * But first, here's how we could append the data as is if we wanted to 
  
```{r}
# This is the quick fix
whr_panel <- bind_rows(whr15, whr16, whr17)
```
  
  * Now, let's take a closer look at the variables in our data sets and see how we can make them compatible

## Exploring a data set (again)

```{r, size = "tiny"}
names(whr15)
names(whr16)
names(whr17)
```

## Exploring a data set (again)

There are a few issues here:

1. The data set for 2017 doesn't include a region identifier
2. The names for the same variables are different in 2017 and 2016 (and the variable names are terrible in general)
3. The data for 2015 only includes the standard error, not the confidence interval

## Subsetting

To fix the first issue, we will merge the region variable from 2016 to the 2017 data set. But first, we need to isolate the variables we actually want to merge to 2017. To do this, we'll use our first `tidyverse` function:

### ``select(.data, ...)``
Keeps only the variables you mention.

* **.data:** a data set
* **...:** one or more unquoted expressions separated by commas indicating the names of the variables you want to keep

## Subsetting

### Exercise 8: subset the data
Create a new object called `regions` containing only the columns `Country` and `Region` of the `whr16` data set.

## Subsetting

```{r}
# Subset the whr 16 data set
regions <- select(whr16, Country, Region)

# Here's what the new dataset looks like
str(regions)
```

## Subsetting 
```{r, size = "footnotesize"}
# This also works with a vector of variables
keepVars <-   c("Country",
                "Region",
                "year",
                "Happiness.Rank",
                "Happiness.Score",
                "Economy..GDP.per.Capita.", 
                "Family",
                "Health..Life.Expectancy.",
                "Freedom",
                "Trust..Government.Corruption.",
                "Generosity",
                "Dystopia.Residual")

whr15 <- whr15[, keepVars]
whr16 <- select(whr16, keepVars)
```
```{r, eval = FALSE, size = "footnotesize"}
whr17 <- select(whr17, keepVars)
```
\footnotesize
\textcolor{red}{\texttt{Error: Unkown column `Region`}}


## Tidyverse

  * As you might have noticed, the `tidyverse` functions have a syntax that is a little bit different from most R functions
  * Its first argument is the name of a data set
  * The following arguments are variable names
  * You don't need to write variable names in quotes
  * You don't need to name your arguments (and it will break if they are in the wrong order)

## Merging

 * The `tidyverse` package `dplyr` has a whole family of functions to do merging. You can look them up by typing `?join`
 * The different `join` functions have a similar function to the `keep` and `keepusing` options of Stata's `merge` function
 * We now want to merge the values in the `regions` object to the `whr17` object, keeping all observations in `whr17`, regardless of them having matches or not
 
## Merging

### ``left_join(x, y, by)``
Return all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.

* **x, y:** data sets to join
* **by:** a character vector of variables to join by. If NULL, the default, *_join() will do a natural join, using all variables with common names across the two tables. 

## Merging 

### Exercise 9: Merge
Merge the `regions` data set into the `whr17` data set.

## Merging

```{r, size = "tiny"}
# Merge
whr17 <- left_join(whr17, regions)

# See the result
str(whr17)
```

## Missing values

```{r, size = "tiny"}
# Did that solve it?
any(is.na(whr17$Region))
sum(is.na(whr17$Region))

# Where is it still missing?
whr17$Country[is.na(whr17$Region)]

# Let's fix that
whr17$Region[whr17$Country %in% c("Mozambique",
                                  "Lesotho",
                                  "Central African Republic")] <-
  "Sub-Saharan Africa"

# That's better
any(is.na(whr17$Region))
```

## Renaming variables

The second problem we found, of different names for the same variable in different data sets, can be easily fixed with the rename function:

```{r}
# Rename function: new name on the left!
whr17 <- rename(whr17,
                Lower.Confidence.Interval = Whisker.low,
                Upper.Confidence.Interval = Whisker.high)
```

## Renaming

  * If you need to change the name of variables in bulk, setting the whole vector of variable names would be easier, as in the example below
  * However, to do that you need to be sure that the variables are in the right order!
  
## Renaming
```{r, size = "tiny"}
# Bulk rename
names(whr15)

newnames <-  c("country",
               "region",
               "year",
               "happy_rank",
               "happy_score",
               "gdp_pc",
               "family",
               "health",
               "freedom",
               "trust_gov_corr",
               "generosity",
               "dystopia_res")

names(whr15) <-  newnames

```

## Ordering variables

Fortunately, `select` also does that for you
```{r}
# Subset the 2017 data set and order variables
whr17 <- select(whr17, keepVars)

# Rename variables
names(whr16) <-  newnames
names(whr17) <-  newnames

# Now we can append safely
whr_panel <- rbind(whr15, whr16, whr17)
```

# Adding variables


## Creating variables based on a formula

  * When we created the `year` variable, we just assigned a value to a column in the data frames using `$`
  * This is great for simple variables, but can get tricky if it takes more complex values
  * For example, to create a dummy variable that shows if the happy score is above the median, we would write the following
  
```{r, eval = F}
# Using $
whr_panel$happy_high <- 
  whr_panel$happy_score > median(whr_panel$happy_score)
```
  
  * The `tidyverse` function `mutate` make this process simpler
  
## Creating variables base on a formula

### `mutate(.data, ...)`
Adds new variables and preserves existing

  * ** .data: ** the data set you want to add a variable to
  * **...:** name-value pairs of expressions. Use NULL to drop a variable
  

## Creating variables base on a formula

### Exercise 10: Create a variable based on a formula
Use the `mutate` function to create a variable called `happy_high` in the `whr_panel` data set indicating whether the `happy_score` is above the median.

- TIP: as usual in `tidyverse`, you can refer to variables by their names, without quotes or `$`

## Creating variables based on a formula

```{r}
# Adding a new variable
whr_panel <- 
  mutate(whr_panel, 
         happy_high = happy_score > median(happy_score))
```

## Creating variables based on a formula

```{r}
# You can do this for multiple variables at a time
whr_panel <- mutate(whr_panel, 
                    happy_high = happy_score > median(happy_score),
                    happy_low = happy_score < median(happy_score),
                    dystopia_res = NULL) # NULL drop the variable
```

## Creating factor variables

  * When we imported this data set, we told R explicitly to not read strings as factor
  * We did that because we knew that we'd have to fix the country names
  * The region variable, however, should be a factor:

```{r, size = "tiny"}
str(whr_panel$region)
unique(whr_panel$region)
```

## Creating a factor

To create a factor variable, we use the ``factor`` function:

### ``factor(x, levels, labels)`` : turns numeric or string vector ``x`` into a factor vector
* **``x``:** the vector you want to turn into a factor
* **``levels``:** a vector containing the possible values of ``x``
* **``labels``:** a vector of strings containing the labels you want to apply to your factor variable
* **``ordered``:** logical flag to determine if the levels should be regarded as ordered (in the order given).

## Converting strings into factors

### Exercise 11: turn a variable into a factor
Use the `mutate` function to create a variable called `region_cat` containing a categorical version of the `region` variable.

- TIP: to do this, you only need the first argument of the `factor` function

## Converting strings into factors
```{r}
# Create categorical region
whr_panel <- 
  mutate(whr_panel,
         region_cat = factor(region))


class(whr_panel$region_cat)
levels(whr_panel$region_cat)
```

## Labelling values

The `labels` argument of the `factor` function can be used to assign labels to specific values

```{r}
# Assign 'not so happy'  and 'happy' as labels
# for above of below median happy score, respectively
whr_panel <- 
  mutate(whr_panel,
         happy_cat = factor(happy_high,
                            levels = c(FALSE, TRUE),
                            labels = c("Not so happy", "Happy")))

table(whr_panel$happy_cat)
```

## Ordering factors

The `ordered` argument of the `factor` function can be used tell R to always display the categories in a certain order.

```{r}
# Assign 'not so happy'  and 'happy' as labels
# for above of below median happy score, respectively
whr_panel <- 
  mutate(whr_panel,
         happy_ord = factor(happy_high,
                            levels = c(FALSE, TRUE),
                            labels = c("Not so happy", "Happy"),
                            ordered = TRUE))

table(whr_panel$happy_ord)
```

# Reshaping

## `spread` and `gather`

These are the tidyverse functions to reshape
```{r}
whr_happy_wide <- spread(whr_happy,
                         key = year,
                         value = happy)

whr_happy_long <- gather(whr_happy_wide,
                         key = year,
                         value = happy,
                         `2015`, `2016`, `2017`)

```

## `reshape`

This is more similar to Stata

# Saving a data set

## Saving a data set to csv

* As mentioned before, R data sets are often save as CSVs
* To save a data set, we use the ``write.csv()`` function:

### ``write.csv(x, file, row.names = TRUE)``
* **``x``:** the object (usually a data frame) you want to export to CSV
* **``file``:** the file path to where you want to save it, including the file name and the format (".csv")
* **``row.names``**: by default, R adds a column to the CSV file with the names (or numbers) of the rows in the data frame. Set it to ``FALSE`` if you don't want that column to be exported


## Saving a data set

### Exercise 12: save the data set

Save the ``whr_panel`` data set to DataWork > DataSets > Final.

* TIP: Use the ``file.path()`` function and the object ``finalData`` created in the master to simplify the folder path.

## Saving a data set

```{r, eval = F}
# Save the lwh data set
write.csv(whr_panel,
          file.path(finalData,"whr_panel.csv"),
          row.names = F)
```

## Saving a data set to .Rdata

* The problem with CSVs is that they cannot differentiate between strings and factors
* They also don't save factor orders
* Data attributes are also lost in csv data


# Appendix

## Saving a data set to Stata

### ``write.dta13(data, file)``
Writes a Stata dta-file bytewise and saves the data into a dta-file.

* **data:** A data frame
* **file:** Path to the dta file you want to export

## Loading a Stata data set
\scriptsize

```{r}
# Export it 
save.dta13(whr_panel,
           file.path(finalData,
                     "whr_panel.dta"))

# Load it again
whr_panel <- read.dta13(file.path(finalData,
                                 "whr_panel.dta"))
```


